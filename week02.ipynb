{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kangwonlee/pytorch-ibm-coursera/blob/main/week02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello PyTorch üëãüèª\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "references\n",
    "* https://www.coursera.org/learn/deep-neural-networks-with-pytorch/\n",
    "* https://github.com/damounayman/Deep-Neural-Networks-with-PyTorch/blob/main/Week1/1D_tensors.ipynb\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## week 2\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Linear Regression in 1D Forward Prediction\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Linear Regression\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\hat y =b+wx$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "b = torch.tensor(-1.0, requires_grad=True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def forward(x):\n",
    "  y = w * x + b\n",
    "  return y\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0])\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "yhat = forward(x)\n",
    "yhat\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "$x =\n",
    "  \\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    2\n",
    "  \\end{pmatrix}$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor(\n",
    "    [\n",
    "        [1.0],\n",
    "        [2.0]\n",
    "    ],\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "forward(x)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### `Linear` class\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "$\\hat y_{1 \\times 1} =b_{1 \\times 1}+w_{1 \\times 1}x_{1 \\times 1}$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model = torch.nn.Linear(in_features=1, out_features=1)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "$b_{1 \\times 1}$ and $w_{1 \\times 1}$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "for p in model.parameters():\n",
    "  print(p)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([0.0])\n",
    "yhat = model(x)\n",
    "yhat\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "$x =\n",
    "  \\begin{pmatrix}\n",
    "    1 \\\\\n",
    "    2\n",
    "  \\end{pmatrix}$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor(\n",
    "    [\n",
    "        [1.0],\n",
    "        [2.0]\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "yhat = model(x)\n",
    "yhat\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Custom Modules\n",
    "* may include multiple models\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class LR(torch.nn.Module):\n",
    "  def __init__(self, in_size, output_size):\n",
    "    super(LR, self).__init__()\n",
    "    self.linear = torch.nn.Linear(in_size, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.linear(x)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = LR(1, 1)\n",
    "\n",
    "state = model.state_dict()\n",
    "\n",
    "weight = state['linear.weight']\n",
    "weight.data[0] = torch.tensor([0.5153])\n",
    "\n",
    "bias = state['linear.bias']\n",
    "bias.data[0] = torch.tensor([-0.4414])\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "$b_{1 \\times 1}$ and $w_{1 \\times 1}$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "for p in model.parameters():\n",
    "  print(p)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.0])\n",
    "model(x)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.tensor(\n",
    "    [\n",
    "        [1.0],\n",
    "        [2.0]\n",
    "    ]\n",
    ")\n",
    "model(x)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "state = model.state_dict()\n",
    "state\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Linear Regression in 1D Training\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Linear Regression\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cost function\n",
    "$$\n",
    "l(w, b)=\\frac{1}{N}\n",
    "  \\sum_{n=1}^N\n",
    "    \\left(\n",
    "      y_n - \\left(\n",
    "          wx_n + b\n",
    "        \\right)\n",
    "    \\right)^2\n",
    "$$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gradient Descent\n",
    "$$\n",
    "w^{k+1}=w^{k}-Œ∑ \\frac{d}{dw}l\\left(w^k\\right)\n",
    "$$\n",
    "\n",
    "symbol | description\n",
    ":------:|-----\n",
    "$w$ | weight\n",
    "$l(w)$ | loss as a function of weigth\n",
    "$$\\frac{d}{dw}l(w)$$ | slope of loss as a function of weigth\n",
    "$k$ | training step\n",
    "$\\eta$ | **learning rate**\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### PyTorch Slope\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w = torch.tensor(-10.0, requires_grad=True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X = torch.linspace(-3, 3, 61).view(-1, 1)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "f = -3 * X\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Y = f + 0.1 * torch.randn(X.size())\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_forward(X, f, Y, flabel='truth', Ylabel='measurements'):\n",
    "  try:\n",
    "    plt.plot(X.numpy(), f.numpy(), label=flabel)\n",
    "  except RuntimeError:\n",
    "    plt.plot(X.numpy(), f.detach().numpy(), label=flabel)\n",
    "\n",
    "  try:\n",
    "    plt.plot(X.numpy(), Y.numpy(), '.', label=Ylabel)\n",
    "  except RuntimeError:\n",
    "    plt.plot(X.numpy(), Y.detach().numpy(), '.', label=Ylabel)\n",
    "\n",
    "  plt.xlabel('X')\n",
    "  plt.ylabel('f')\n",
    "  plt.legend(loc=0)\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_forward(X, f, Y)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def forward(x):\n",
    "  return w * x\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def criterion(yhat, y):\n",
    "  return torch.mean((yhat - y) ** 2)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_cost(weight, cost):\n",
    "  plt.plot(weight, cost, '.-')\n",
    "  plt.xlabel('w')\n",
    "  plt.ylabel('cost')\n",
    "  plt.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO : factor into a training function\n",
    "\n",
    "# learning rate\n",
    "lr = 0.1\n",
    "lr_neg = -lr\n",
    "\n",
    "weight = []\n",
    "cost_batch_gradient_descent = []\n",
    "\n",
    "# epoch : training steps\n",
    "for epoch in range(4):\n",
    "  Yhat = forward(X)\n",
    "\n",
    "  loss = criterion(Yhat, Y)\n",
    "  loss.backward()\n",
    "\n",
    "  w.data += (lr_neg) * w.grad.data\n",
    "  w.grad.data.zero_()\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.subplot(2, 1, 1)\n",
    "  weight.append(w.data.item())\n",
    "  cost_batch_gradient_descent.append(loss.item())\n",
    "  plot_cost(weight, cost_batch_gradient_descent)\n",
    "\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plot_forward(X, Yhat, Y, 'prediction', 'data')\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Cost Surface\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "in PyTorch, the hard way\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def forward(x):\n",
    "  return w * x + b\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "cost function\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def criterion(yhat, y):\n",
    "  return torch.mean((yhat-y) ** 2)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize tensors\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "w = torch.tensor(-15.0, requires_grad=True)\n",
    "b = torch.tensor(-10.0, requires_grad=True)\n",
    "X = torch.linspace(-3.0, 3.0, 61).view(-1, 1)\n",
    "f = 1.0 * X - 1.0\n",
    "Y = f + 0.1 * torch.randn(X.size())\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check sizes\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\hat y &= wx+b \\\\\n",
    "  {\\hat y}_{pq \\times n} &= \\begin{pmatrix}\n",
    "    w_{p q \\times 1} & b_{p q \\times 1}\n",
    "  \\end{pmatrix}_{pq \\times 2}\n",
    "  \\begin{pmatrix}\n",
    "    x_{1 \\times n} \\\\ 1_{1 \\times n}\n",
    "  \\end{pmatrix}_{2 \\times n} \\\\\n",
    "error_{p q \\times n}&={\\hat y}_{pq \\times n} - 1_{pq \\times 1} y_{1 \\times n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def calc_cost_surface(\n",
    "    w_range:int, b_range:int,\n",
    "    X:torch.tensor, Y:torch.tensor,\n",
    "    n_samples:int=31,\n",
    "  ):\n",
    "  w_vec = np.linspace(-w_range, w_range, n_samples)\n",
    "  b_vec = np.linspace(-b_range, b_range, n_samples)\n",
    "\n",
    "  w_grid, b_grid = np.meshgrid(w_vec, b_vec)\n",
    "\n",
    "  x = X.numpy().reshape(1, -1)\n",
    "  y = Y.numpy().reshape(1, -1)\n",
    "  x_one = np.vstack([\n",
    "    x,\n",
    "    np.ones_like(x)\n",
    "  ])\n",
    "\n",
    "  w_flat = w_grid.flatten()\n",
    "  b_flat = b_grid.flatten()\n",
    "  wb = np.column_stack([w_flat, b_flat])\n",
    "\n",
    "  assert wb.shape[-1] == x_one.shape[0], (\n",
    "      '\\n'\n",
    "      f\"w_flat.shape = {w_flat.shape}\\n\"\n",
    "      f\"wb.shape = {wb.shape}\\n\"\n",
    "      f\"x_one.shape = {x_one.shape}\\n\"\n",
    "  )\n",
    "  yhat = wb @ x_one\n",
    "\n",
    "  ones_y = np.ones((len(w_flat), 1))\n",
    "\n",
    "  # using numpy broadcasting along the first dimension\n",
    "  # yhat [pq, n]\n",
    "  # y[1, n]\n",
    "  error = yhat - y\n",
    "  z_flat = np.mean(error**2, axis=1)\n",
    "\n",
    "  Z = z_flat.reshape(*w_grid.shape)\n",
    "\n",
    "  return w_grid, b_grid, Z\n",
    "\n",
    "\n",
    "w_grid, b_grid, Z = calc_cost_surface(15, 15, X, Y)\n",
    "\n",
    "_, axs = plt.subplots(1, 2, subplot_kw={'projection':'3d'})\n",
    "ax = axs[0]\n",
    "ax.contour(w_grid, b_grid, Z)\n",
    "ax.set_xlabel('w')\n",
    "ax.set_ylabel('b')\n",
    "ax.set_zlabel('l(w,b)')\n",
    "ax.grid(True)\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot_surface(w_grid, b_grid, Z)\n",
    "ax.set_xlabel('w')\n",
    "ax.set_ylabel('b')\n",
    "ax.set_zlabel('l(w,b)')\n",
    "ax.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_cost_surface(\n",
    "    w_range:int, b_range:int,\n",
    "    X:torch.tensor, Y:torch.tensor,\n",
    "    n_samples:int=31,\n",
    "    ax=None\n",
    "):\n",
    "\n",
    "    w_grid, b_grid, Z = calc_cost_surface(\n",
    "        w_range=w_range,\n",
    "        b_range=b_range,\n",
    "        X=X,\n",
    "        Y=Y,\n",
    "        n_samples=n_samples,\n",
    "    )\n",
    "\n",
    "    if ax is None:\n",
    "      ax = plt.gca()\n",
    "\n",
    "    assert 2 <= len(w_grid.shape), w_grid.shape\n",
    "    assert 2 <= len(b_grid.shape), b_grid.shape\n",
    "    assert 2 <= len(Z.shape), Z.shape\n",
    "\n",
    "    ax.contour(w_grid, b_grid, Z)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO : factor into a training function\n",
    "lr = 0.1\n",
    "lr_neg = -lr\n",
    "\n",
    "w_list = []\n",
    "b_list = []\n",
    "loss_list = []\n",
    "\n",
    "ax = plt.gca()\n",
    "plot_cost_surface(15, 15, X, Y, ax=ax)\n",
    "\n",
    "for epoch in range(15):\n",
    "\n",
    "  Yhat = forward(X)\n",
    "  loss = criterion(Yhat, Y)\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  ax.plot([w.data.item()], [b.data.item()], '.')\n",
    "  ax.plot(\n",
    "      [w.data.item(), w.data.item()+(lr_neg)*w.grad.data.item()],\n",
    "      [b.data.item(), b.data.item()+(lr_neg)*b.grad.data.item()],\n",
    "      '-'\n",
    "  )\n",
    "\n",
    "  w.data += (lr_neg) * w.grad.data\n",
    "  w.grad.data.zero_()\n",
    "\n",
    "  b.data += (lr_neg) * b.grad.data\n",
    "  b.grad.data.zero_()\n",
    "\n",
    "  w_list.append(w.data.item())\n",
    "  b_list.append(b.data.item())\n",
    "  loss_list.append(loss.data.item())\n",
    "\n",
    "ax.set_xlabel('w')\n",
    "ax.set_ylabel('b')\n",
    "ax.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Stochastic Gradient Descent & the Data Loader\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Truth & Measurement\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "w = torch.tensor(-15.0, requires_grad=True)\n",
    "b = torch.tensor(-10.0, requires_grad=True)\n",
    "\n",
    "X = torch.linspace(-3, 3, 61).view(-1, 1)\n",
    "f = (-3) * X\n",
    "Y = f + 0.1 * torch.randn(X.size())\n",
    "\n",
    "plt.plot(X.numpy(), f.numpy(), label='f')\n",
    "plt.plot(X.numpy(), Y.numpy(), '.', label='Y')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stochastic Gradient Descent updates weights at each data point\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO : factor into a training function\n",
    "# learning rate\n",
    "lr = 0.1\n",
    "lr_neg = -lr\n",
    "\n",
    "weight = []\n",
    "cost_stochastic_gradient_descent = []\n",
    "\n",
    "w_list = []\n",
    "b_list = []\n",
    "\n",
    "for epoch in range(4):\n",
    "\n",
    "  total = 0\n",
    "\n",
    "  for x, y in zip(X, Y):\n",
    "    yhat = forward(x)\n",
    "\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "\n",
    "    w.data += (lr_neg) * w.grad.data\n",
    "    b.data += (lr_neg) * b.grad.data\n",
    "\n",
    "    w_list.append(w.data.item())\n",
    "    b_list.append(b.data.item())\n",
    "\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    total += loss.item()\n",
    "\n",
    "    weight.append(w.data.item())\n",
    "    cost_stochastic_gradient_descent.append(loss.item())\n",
    "\n",
    "  cost_stochastic_gradient_descent.append(total)\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plot_forward(X, forward(X), Y, 'prediction', 'data')\n",
    "\n",
    "  ax = plt.subplot(1, 2, 2)\n",
    "  plot_cost_surface(15, 15, X, Y, ax=ax)\n",
    "  plt.plot(w_list, b_list, '.')\n",
    "  plt.plot(w_list[0], b_list[0], 'o')\n",
    "  plt.xlabel('w')\n",
    "  plt.ylabel('b')\n",
    "  plt.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Loader\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.utils.data\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "  def __init__(self):\n",
    "    self.x = torch.linspace(-3, 3, 61).view(-1, 1)\n",
    "    self.f = -3 * self.x + 1\n",
    "    self.y = self.f + 0.1 * torch.randn(self.x.size())\n",
    "    self.len = self.x.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.x[index], self.y[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = Data()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "First element\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "x, y = dataset[0]\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Slicing\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "x, y = dataset[:3]\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Declare a DataLoader\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = Data()\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w = torch.tensor(-15.0, requires_grad=True)\n",
    "b = torch.tensor(-10.0, requires_grad=True)\n",
    "\n",
    "X = torch.linspace(-3, 3, 61).view(-1, 1)\n",
    "f = (-3) * X\n",
    "Y = f + 0.1 * torch.randn(X.size())\n",
    "\n",
    "plt.plot(X.numpy(), f.numpy(), label='f')\n",
    "plt.plot(X.numpy(), Y.numpy(), '.', label='Y')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f')\n",
    "plt.legend(loc=0)\n",
    "\n",
    "plt.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO : factor into a training function\n",
    "# learning rate\n",
    "lr = 0.1\n",
    "lr_neg = -lr\n",
    "\n",
    "weight = []\n",
    "\n",
    "epoch_list = []\n",
    "cost_stochastic_gradient_descent = []\n",
    "\n",
    "w_list = []\n",
    "b_list = []\n",
    "\n",
    "# epoch : training steps\n",
    "for epoch in range(15):\n",
    "\n",
    "  total = 0\n",
    "\n",
    "  # zip(X, Y) -> trainloader\n",
    "  for k, (x, y) in enumerate(trainloader):\n",
    "    yhat = forward(x)\n",
    "\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "\n",
    "    w.data += (lr_neg) * w.grad.data\n",
    "    b.data += (lr_neg) * b.grad.data\n",
    "\n",
    "    w_list.append(w.data.item())\n",
    "    b_list.append(b.data.item())\n",
    "\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    total += loss.item()\n",
    "\n",
    "    weight.append(w.data.item())\n",
    "\n",
    "    epoch_list.append(epoch + k/len(trainloader))\n",
    "    cost_stochastic_gradient_descent.append(total)\n",
    "\n",
    "  # end population loop\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plot_forward(X, forward(X), Y, 'prediction', 'data')\n",
    "\n",
    "  ax = plt.subplot(1, 2, 2)\n",
    "  plot_cost_surface(15, 15, X, Y, ax=ax)\n",
    "  plt.plot(w_list, b_list, '.')\n",
    "  plt.plot(w_list[0], b_list[0], 'o')\n",
    "  plt.xlabel('w')\n",
    "  plt.ylabel('b')\n",
    "  plt.grid(True)\n",
    "# end epoch loop\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Batch Gradient Descent\n",
    "* To compare cost change over epoch\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "w = torch.tensor(-15.0, requires_grad=True)\n",
    "b = torch.tensor(-10.0, requires_grad=True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO : factor into a training function\n",
    "\n",
    "lr = 0.1\n",
    "lr_neg = -lr\n",
    "\n",
    "w_list = []\n",
    "b_list = []\n",
    "cost_batch_gradient_descent = []\n",
    "\n",
    "for epoch in range(15):\n",
    "  Yhat = forward(X)\n",
    "  loss = criterion(Yhat, Y)\n",
    "\n",
    "  loss.backward()\n",
    "\n",
    "  w.data += (lr_neg) * w.grad.data\n",
    "  w.grad.data.zero_()\n",
    "\n",
    "  b.data += (lr_neg) * b.grad.data\n",
    "  b.grad.data.zero_()\n",
    "\n",
    "  w_list.append(w.data.item())\n",
    "  b_list.append(b.data.item())\n",
    "  cost_batch_gradient_descent.append(loss.data.item())\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(cost_batch_gradient_descent, 'o-', label='Batch Gradient Descent')\n",
    "plt.plot(\n",
    "    epoch_list,\n",
    "    cost_stochastic_gradient_descent,\n",
    "    label='Stochastic Gradient Descent'\n",
    ")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('cost / total loss')\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Mini-Batch Gradient Descent\n",
    "* Large data\n",
    "* If Batch size = 2\n",
    "* First iteration\n",
    "$$\n",
    "l_1(w,b)=\\frac{1}{2}\n",
    "  \\left[\n",
    "    \\left(\n",
    "      y_1 - (w x_1 + b)\n",
    "    \\right)^2\n",
    "    +\n",
    "    \\left(\n",
    "      y_2 - (w x_2 + b)\n",
    "    \\right)^2\n",
    "  \\right]\n",
    "$$\n",
    "* Second iteration\n",
    "$$\n",
    "l_2(w,b)=\\frac{1}{2}\n",
    "  \\left[\n",
    "    \\left(\n",
    "      y_3 - (w x_3 + b)\n",
    "    \\right)^2\n",
    "    +\n",
    "    \\left(\n",
    "      y_4 - (w x_4 + b)\n",
    "    \\right)^2\n",
    "  \\right]\n",
    "$$\n",
    "* and so on\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = Data()\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=5,\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "w = torch.tensor(-15.0, requires_grad=True)\n",
    "b = torch.tensor(-10.0, requires_grad=True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# TODO : factor into a training function\n",
    "\n",
    "# learning rate\n",
    "lr = 0.1\n",
    "lr_neg = -lr\n",
    "\n",
    "weight = []\n",
    "\n",
    "w_list = []\n",
    "b_list = []\n",
    "epoch_list = []\n",
    "cost_mini_batch_gradient_descent = []\n",
    "\n",
    "for epoch in range(15):\n",
    "\n",
    "  total = 0\n",
    "\n",
    "  epoch_list.append(epoch)\n",
    "  cost_mini_batch_gradient_descent.append(total)\n",
    "\n",
    "  # zip(X, Y) -> trainloader\n",
    "  for k, (x, y) in enumerate(trainloader):\n",
    "    yhat = forward(x)\n",
    "\n",
    "    loss = criterion(yhat, y)\n",
    "    loss.backward()\n",
    "\n",
    "    w.data += (lr_neg) * w.grad.data\n",
    "    b.data += (lr_neg) * b.grad.data\n",
    "\n",
    "    w_list.append(w.data.item())\n",
    "    b_list.append(b.data.item())\n",
    "\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    total += loss.item()\n",
    "\n",
    "    weight.append(w.data.item())\n",
    "\n",
    "    epoch_list.append(epoch + k/len(trainloader))\n",
    "    cost_mini_batch_gradient_descent.append(total)\n",
    "\n",
    "  # end population loop\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plot_forward(X, forward(X), Y, 'prediction', 'data')\n",
    "\n",
    "  ax = plt.subplot(1, 2, 2)\n",
    "  plot_cost_surface(15, 15, X, Y, ax=ax)\n",
    "  plt.plot(w_list, b_list, '.')\n",
    "  plt.plot(w_list[0], b_list[0], 'o')\n",
    "  plt.xlabel('w')\n",
    "  plt.ylabel('b')\n",
    "  plt.grid(True)\n",
    "# end epoch loop\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(cost_batch_gradient_descent, 'o-', label='Batch Gradient Descent')\n",
    "plt.plot(\n",
    "    epoch_list,\n",
    "    cost_mini_batch_gradient_descent,\n",
    "    label='Mini-Batch Gradient Descent'\n",
    ")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('cost / total loss')\n",
    "plt.legend(loc=0)\n",
    "plt.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Optimization in PyTorch\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn\n",
    "import torch.optim\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear Regression Model\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model = LR(1, 1)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.x = torch.linspace(-3, 3, 61).view(-1, 1)\n",
    "    # truth\n",
    "    self.f = 1 * self.x - 1\n",
    "    # contaminated measurement\n",
    "    self.y = self.f + 0.1 * torch.randn(self.x.size())\n",
    "    self.len = self.x.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.x[index], self.y[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_LR(\n",
    "    n_epoch=100,\n",
    "    batch_size=1,\n",
    "    learning_rate=0.01,\n",
    "    criterion=torch.nn.MSELoss(),\n",
    "    model=LR(1,1),\n",
    "    dataset=Data(),\n",
    "    loss_list=[],\n",
    "    param_list=[],\n",
    "    weight_init=-15.0,\n",
    "    bias_init=-10.0\n",
    "  ):\n",
    "\n",
    "  # initialize weight & bias\n",
    "  state_dict = model.state_dict()\n",
    "  state_dict['linear.weight'][0] = weight_init\n",
    "  state_dict['linear.bias'][0] = bias_init\n",
    "\n",
    "  # DataLoader object\n",
    "  trainloader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=1,\n",
    "  )\n",
    "\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.SGD(\n",
    "      model.parameters(),\n",
    "      lr=learning_rate\n",
    "    )\n",
    "\n",
    "  epoch_list = []\n",
    "\n",
    "  for epoch in range(n_epoch):\n",
    "    total = 0\n",
    "\n",
    "    for k, (x, y) in enumerate(trainloader):\n",
    "      yhat = model(x)\n",
    "      loss = criterion(yhat, y)\n",
    "      total += loss.item()\n",
    "\n",
    "      epoch_list.append(epoch + k/len(trainloader))\n",
    "      loss_list.append(total)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      # differentiate loss\n",
    "      loss.backward()\n",
    "      # implicitly linked to the derivatives\n",
    "      optimizer.step()\n",
    "      param_list.append(\n",
    "          [p.item() for p in model.parameters()]\n",
    "      )\n",
    "    # end iteration loop\n",
    "  # end epoch loop\n",
    "\n",
    "  return {\n",
    "      'model':model,\n",
    "      'epoch_list': epoch_list,\n",
    "      'loss_list': loss_list,\n",
    "      'param_list': param_list,\n",
    "      'dataset': dataset,\n",
    "  }\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Loss_Optim = []\n",
    "d = train_LR(n_epoch=10, loss_list=Loss_Optim)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.loglog(\n",
    "    d['epoch_list'], d['loss_list'],\n",
    "    '.-', label='PyTorch Optimizer'\n",
    ")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ax = plt.gca()\n",
    "\n",
    "X, Y = d['dataset'][:]\n",
    "plot_cost_surface(15, 15, X, Y, ax=ax)\n",
    "\n",
    "wb = np.array(d['param_list']).T\n",
    "\n",
    "w = wb[0, :].squeeze()\n",
    "b = wb[1, :].squeeze()\n",
    "\n",
    "ax.plot(w, b, '.-')\n",
    "ax.plot(w[0], b[0], 'o')\n",
    "\n",
    "ax.set_xlabel('w')\n",
    "ax.set_ylabel('b')\n",
    "\n",
    "ax.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}