{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kangwonlee/pytorch-ibm-coursera/blob/main/week05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello PyTorch 👋🏻\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "references\n",
    "* https://www.coursera.org/learn/deep-neural-networks-with-pytorch/\n",
    "* https://github.com/damounayman/Deep-Neural-Networks-with-PyTorch/blob/main/Week1/1D_tensors.ipynb\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## week 5\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.1 Deep Neural Networks\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### MNIST dataset\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import functools\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Net(torch.nn.Module):\n",
    "  def __init__(self, layers:List[int], act=torch.nn.ReLU(), n_input:int=None):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    if n_input is None:\n",
    "      self.n_input = layers[0]\n",
    "    else:\n",
    "      self.n_input = n_input\n",
    "\n",
    "    assert len(layers) > 2, f'len(argv) = {len(layers)}'\n",
    "\n",
    "    self.hidden = torch.nn.ModuleList([])\n",
    "\n",
    "    for n_in, n_out in zip(layers[:-1], layers[1:]):\n",
    "      self.hidden.append(torch.nn.Linear(n_in, n_out))\n",
    "\n",
    "    self.act = act\n",
    "\n",
    "  def forward(self, x):\n",
    "    for layer in self.hidden[:-1]:\n",
    "      x = self.act(layer(x))\n",
    "\n",
    "    return self.hidden[-1](x)\n",
    "\n",
    "  def plot_activation(self, Y, X):\n",
    "      a1 = torch.sigmoid(self.linears[0](X))\n",
    "      plt.scatter(\n",
    "          a1.detach().numpy()[:, 0],\n",
    "          a1.detach().numpy()[:, 1],\n",
    "          c=Y.numpy().reshape(-1)\n",
    "      )\n",
    "      plt.title('activations')\n",
    "      plt.grid(True)\n",
    "\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html\n",
    "# https://stackoverflow.com/questions/50463975/pytorch-how-to-properly-create-a-list-of-nn-linear\n",
    "# https://discuss.pytorch.org/t/when-should-i-use-nn-modulelist-and-when-should-i-use-nn-sequential/5463\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "@functools.lru_cache\n",
    "def load_MNIST_torchvision(root:str='./data'):\n",
    "  '''\n",
    "  [[image, class], ...]\n",
    "  '''\n",
    "\n",
    "  train_dataset = torchvision.datasets.MNIST(\n",
    "      root=root,\n",
    "      train=True,\n",
    "      download=True,\n",
    "      transform=torchvision.transforms.ToTensor(),\n",
    "  )\n",
    "\n",
    "  test_dataset = torchvision.datasets.MNIST(\n",
    "      root=root,\n",
    "      train=False,\n",
    "      download=True,\n",
    "      transform=torchvision.transforms.ToTensor(),\n",
    "  )\n",
    "\n",
    "  return {\n",
    "      'train': train_dataset,\n",
    "      'validation': test_dataset,\n",
    "  }\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "d_mnist = load_MNIST_torchvision()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "input_dim = 28 * 28\n",
    "n_hidden = 100\n",
    "n_hidden2 = 50\n",
    "n_class = 10\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=d_mnist['train'], batch_size=2000,\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset=d_mnist['validation'], batch_size=5000,\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_validate(\n",
    "    model, optimizer, criterion,\n",
    "    train_loader,\n",
    "    validation_loader=[],\n",
    "    n_epoch:int=1000,\n",
    "  ) -> Dict[str, List[float]]:\n",
    "  record = {\n",
    "    'training_loss': [],\n",
    "    'validation_accuracy': [],\n",
    "  }\n",
    "\n",
    "  if os.getenv('CI', False):\n",
    "    n_epoch = 1\n",
    "\n",
    "  for epoch in range(n_epoch):\n",
    "    total = 0.0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      yhat = model(x.view(-1, model.n_input))\n",
    "\n",
    "      loss = criterion(yhat, y)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "      total += loss.item()\n",
    "\n",
    "      record['training_loss'].append(loss.item())\n",
    "\n",
    "    # end train_loader loop\n",
    "\n",
    "    correct = 0\n",
    "    population = 0\n",
    "    for x, y in validation_loader:\n",
    "      z = model(x.view(-1, 28*28))\n",
    "      _, label = torch.max(z, 1)\n",
    "      correct += (label==y).sum().item()\n",
    "      population += len(y)\n",
    "    # end validation_loader loop\n",
    "\n",
    "    if population:\n",
    "      accuracy = 100.0 * (correct / population)\n",
    "      record['validation_accuracy'].append(accuracy)\n",
    "\n",
    "  # end epoch loop\n",
    "  return record\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "ReLu with One hidden layer\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model_iho = Net(\n",
    "    [input_dim, n_hidden, n_class],\n",
    "    act=torch.nn.ReLU(),\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model_iho.parameters(), lr=0.01)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "training_results_iho = train_validate(\n",
    "    model_iho, optimizer, criterion,\n",
    "    train_loader, validation_loader,\n",
    "    n_epoch=1 # set 30 to train\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "training_results_iho['label'] = 'i-h-o'\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "ReLu with Two hidden layers\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model_ihho = Net(\n",
    "    [input_dim, n_hidden2, n_hidden2, n_class],\n",
    "    act=torch.nn.ReLU(),\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model_ihho.parameters(), lr=0.01)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "training_results_ihho = train_validate(\n",
    "    model_ihho, optimizer, criterion,\n",
    "    train_loader, validation_loader,\n",
    "    n_epoch=1 # set 30 to train\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "training_results_ihho['label'] = 'i-h-h-o'\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "more reusable plotter function\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_result(d_list:Dict[str,List[float]]):\n",
    "  _, axs = plt.subplots(2, 1)\n",
    "\n",
    "  for d in d_list:\n",
    "    axs[0].plot(d['training_loss'], label=d['label'])\n",
    "    axs[1].plot(d['validation_accuracy'], label=d['label'])\n",
    "\n",
    "  axs[0].set_xlabel('iter')\n",
    "  axs[0].legend(loc=0)\n",
    "  axs[0].grid(True)\n",
    "\n",
    "  axs[1].set_xlabel('epoch')\n",
    "  axs[1].legend(loc=0)\n",
    "  axs[1].grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_result([training_results_iho, training_results_ihho])\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tanh\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model_tanh = Net(\n",
    "    [input_dim, n_hidden2, n_hidden2, n_class],\n",
    "    act=torch.nn.Tanh(),\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model_tanh.parameters(), lr=0.01)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "training_results_tanh = train_validate(\n",
    "    model_tanh, optimizer, criterion,\n",
    "    train_loader, validation_loader,\n",
    "    n_epoch=1 # set 30 to train\n",
    ")\n",
    "training_results_tanh['label'] = 'tanh'\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_result([training_results_iho, training_results_ihho, training_results_tanh])\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sigmoid\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "model_sigmoid = Net(\n",
    "    [input_dim, n_hidden2, n_hidden2, n_class],\n",
    "    act=torch.nn.Sigmoid(),\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model_sigmoid.parameters(), lr=0.01)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "training_results_sigmoid = train_validate(\n",
    "    model_sigmoid, optimizer, criterion,\n",
    "    train_loader, validation_loader,\n",
    "    n_epoch=1 # set 30 to train\n",
    ")\n",
    "training_results_sigmoid['label'] = 'sigmoid'\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_result([\n",
    "    training_results_iho, training_results_ihho,\n",
    "    training_results_tanh, training_results_sigmoid\n",
    "])\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Spiral dataset\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Data Class\n",
    "\n",
    "class Data(torch.utils.data.Dataset):\n",
    "\n",
    "    #  modified from: http://cs231n.github.io/neural-networks-case-study/\n",
    "    # Constructor\n",
    "    def __init__(self, K=3, N=500):\n",
    "        D = 2\n",
    "        X = np.zeros((N * K, D)) # data matrix (each row = single example)\n",
    "        y = np.zeros(N * K, dtype='uint8') # class labels\n",
    "        for j in range(K):\n",
    "          ix = range(N * j, N * (j + 1))\n",
    "          r = np.linspace(0.0, 1, N) # radius\n",
    "          t = np.linspace(j * 4, (j + 1) * 4, N) + np.random.randn(N) * 0.2 # theta\n",
    "          X[ix] = np.c_[r * np.sin(t), r*np.cos(t)]\n",
    "          y[ix] = j\n",
    "        self.y = torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.x = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "        self.len = y.shape[0]\n",
    "\n",
    "    # Getter\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    # Plot the diagram\n",
    "    def plot_data(self):\n",
    "        plt.plot(self.x[self.y[:] == 0, 0].numpy(), self.x[self.y[:] == 0, 1].numpy(), 'o', label=\"y = 0\")\n",
    "        plt.plot(self.x[self.y[:] == 1, 0].numpy(), self.x[self.y[:] == 1, 1].numpy(), 'ro', label=\"y = 1\")\n",
    "        plt.plot(self.x[self.y[:] == 2, 0].numpy(), self.x[self.y[:] == 2, 1].numpy(), 'go', label=\"y = 2\")\n",
    "        plt.legend()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_set = Data()\n",
    "data_set.plot_data()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=data_set, batch_size=20,\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_spiral = Net(\n",
    "    [2, 10, 10, 3],\n",
    "    act=torch.nn.Tanh(),\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model_spiral.parameters(), lr=0.01)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def pcolor_class(model, data_set):\n",
    "  data_set.plot_data()\n",
    "  xmin = data_set.x[:, 0].min()\n",
    "  xmax = data_set.x[:, 0].max()\n",
    "\n",
    "  ymin = data_set.x[:, 1].min()\n",
    "  ymax = data_set.x[:, 1].max()\n",
    "\n",
    "  x = torch.linspace(xmin, xmax, 101)\n",
    "  y = torch.linspace(ymin, ymax, 101)\n",
    "\n",
    "  X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "  x_flat = torch.hstack([X.reshape(101*101, 1), Y.reshape(101*101, 1)])\n",
    "\n",
    "  _, zhat = torch.max(model(x_flat), 1)\n",
    "\n",
    "  Zhat = zhat.numpy().reshape(X.shape)\n",
    "\n",
    "  ax = plt.gca()\n",
    "  ax.pcolor(X, Y, Zhat)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "result = train_validate(\n",
    "    model=model_spiral, criterion=criterion, optimizer=optimizer,\n",
    "    train_loader=train_loader, n_epoch=1, # 200 to train\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pcolor_class(model_spiral, data_set)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.2 Dropout\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* To prevent overfitting\n",
    "* Training & Evaluation steps\n",
    "* Randomly drop off part of the neurons\n",
    "* $p = 1$ shutdown all neurons\n",
    "* $p$ too small : possible overfitting\n",
    "* $p$ too high : possible underfitting\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class DropoutNet(Net):\n",
    "  def __init__(self, layers:List[int], act=torch.nn.ReLU(), p:float=0, n_input:int=None):\n",
    "    super(DropoutNet, self).__init__(layers, act, n_input)\n",
    "    self.drop = torch.nn.Dropout(p=p)\n",
    "\n",
    "  def forward(self, x):\n",
    "    for layer in self.hidden[:-1]:\n",
    "      x = self.act(layer(x))\n",
    "      x = self.drop(x)\n",
    "    return self.hidden[-1](x)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Data Class\n",
    "\n",
    "class Data(torch.utils.data.Dataset):\n",
    "  def __init__(self, N_SAMPLES=1000, noise_std=0.15, train=True):\n",
    "    a = np.array([[-1, 1, 2, 1, 1, -3, 1]]).T\n",
    "\n",
    "    self.x = np.matrix(np.random.rand(N_SAMPLES, 2))\n",
    "    self.f = np.array(\n",
    "      a[0]\n",
    "      + (self.x) * a[1:3]\n",
    "      + np.multiply(self.x[:, 0], self.x[:, 1]) * a[4]\n",
    "      + np.multiply(self.x, self.x) * a[5:7]\n",
    "    ).flatten()\n",
    "    self.a = a\n",
    "\n",
    "    self.y = np.zeros(N_SAMPLES)\n",
    "    self.y[self.f > 0] = 1\n",
    "    self.y = torch.from_numpy(self.y).type(torch.LongTensor)\n",
    "    self.x = torch.from_numpy(self.x).type(torch.FloatTensor)\n",
    "    self.x += noise_std * torch.randn(self.x.size())\n",
    "    self.f = torch.from_numpy(self.f)\n",
    "    # self.a = a\n",
    "\n",
    "    if train:\n",
    "      torch.manual_seed(1)\n",
    "      self.x += noise_std * torch.randn(self.x.size())\n",
    "      torch.manual_seed(0)\n",
    "\n",
    "    self.len = len(self.x)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.x[index], self.y[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "\n",
    "  # Plot the diagram\n",
    "  def plot_data(self):\n",
    "    for y in range(self.y.min(), self.y.max() + 1):\n",
    "      plt.plot(self.x[self.y[:] == y, 0].numpy(), self.x[self.y[:] == y, 1].numpy(), 'o', label=f'y = {y}')\n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True)\n",
    "\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = DropoutNet([2, 300, 2], p=0.0)\n",
    "model_drop = DropoutNet([2, 300, 2], p=0.5)\n",
    "model_drop.train()\n",
    "# model_drop.eval()\n",
    "\n",
    "optimizer_ofit = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer_drop = torch.optim.Adam(model_drop.parameters(), lr=0.01)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_set = Data()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "validation_set = Data(train=False)\n",
    "\n",
    "def init_loss():\n",
    "  return {\n",
    "    'training data no dropout': [],\n",
    "    'validation data no dropout': [],\n",
    "    'training data dropout': [],\n",
    "    'validation data dropout': [],\n",
    "}\n",
    "\n",
    "LOSS = init_loss()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_dropout(\n",
    "    model, model_dropout,\n",
    "    data_set, validation_set,\n",
    "    criterion,\n",
    "    optimizer_ofit, optimizer_drop,\n",
    "    LOSS, n_epoch=500,\n",
    "  ):\n",
    "  for epoch in range(n_epoch):\n",
    "    yhat = model(data_set.x)\n",
    "    yhat_drop = model_dropout(data_set.x)\n",
    "    loss = criterion(yhat, data_set.y)\n",
    "    loss_drop = criterion(yhat_drop, data_set.y)\n",
    "\n",
    "    LOSS['training data no dropout'].append(loss.item())\n",
    "\n",
    "    v = criterion(model(validation_set.x), validation_set.y)\n",
    "    LOSS['validation data no dropout'].append(v.item())\n",
    "\n",
    "    LOSS['training data dropout'].append(loss_drop.item())\n",
    "    model_drop.eval()\n",
    "    v = criterion(model_dropout(validation_set.x), validation_set.y)\n",
    "    LOSS['validation data dropout'].append(v.item())\n",
    "    model_drop.train()\n",
    "\n",
    "    optimizer_ofit.zero_grad()\n",
    "    optimizer_drop.zero_grad()\n",
    "    loss.backward()\n",
    "    loss_drop.backward()\n",
    "    optimizer_ofit.step()\n",
    "    optimizer_drop.step()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "LOSS = init_loss()\n",
    "train_dropout(\n",
    "    model, model_drop,\n",
    "    data_set, validation_set,\n",
    "    criterion,\n",
    "    optimizer_ofit, optimizer_drop,\n",
    "    LOSS\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pcolor_class(model, data_set)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_drop.eval()\n",
    "pcolor_class(model_drop, data_set)\n",
    "model_drop.train()\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_loss_dict(loss):\n",
    "  for key, value in loss.items():\n",
    "    plt.semilogy(value, label=key)\n",
    "  plt.xlabel('iter')\n",
    "  plt.legend(loc=0)\n",
    "  plt.grid(True)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plot_loss_dict(LOSS)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.3 Neural Network initialization weights\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.4 Gradient Descent with Momentum\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8.5 Batch Normalization\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}