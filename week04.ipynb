{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kangwonlee/pytorch-ibm-coursera/blob/main/week04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello PyTorch 👋🏻\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "references\n",
    "* https://www.coursera.org/learn/deep-neural-networks-with-pytorch/\n",
    "* https://github.com/damounayman/Deep-Neural-Networks-with-PyTorch/blob/main/Week1/1D_tensors.ipynb\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## week 4\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1 Softmax Prediction\n",
    "* To classify more than two classes\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1D\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Three classes:\n",
    "* `y = 0`\n",
    "* `y = 1`\n",
    "* `y = 2`\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import functools\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "x = torch.linspace(-2.0, 2.0, 41)\n",
    "y = (x > -1)*1.0 + (x > 1)*1.0\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_softmax_data_00(x, y, ax=None):\n",
    "\n",
    "  if ax is None:\n",
    "    ax = plt.gca()\n",
    "\n",
    "  x0 = x[y<0.5]\n",
    "  x1 = x[(0.5<y) & (y<1.5)]\n",
    "  x2 = x[1.5 < y]\n",
    "\n",
    "  ax.plot(x0.numpy(), np.zeros(x0.shape), 'b.', label='y=0')\n",
    "  ax.plot(x1.numpy(), np.zeros(x1.shape), 'r.', label='y=1')\n",
    "  ax.plot(x2.numpy(), np.zeros(x2.shape), 'g.', label='y=2')\n",
    "\n",
    "  ax.set_xlabel('x')\n",
    "  ax.legend(loc=0)\n",
    "  ax.grid(True)\n",
    "\n",
    "  return ax\n",
    "\n",
    "\n",
    "plot_softmax_data_00(x, y)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Three functions\n",
    "* $z_0(x) = w_0 x + b_0$\n",
    "* $z_1(x) = w_1 x + b_1$\n",
    "* $z_2(x) = w_2 x + b_2$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classification\n",
    "* $\\hat {\\theta} = \\underset{i}{argmax}z_i(x)$\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_softmax_lines_01(x, ax=None):\n",
    "\n",
    "  if ax is None:\n",
    "    ax = plt.gca()\n",
    "\n",
    "  w0, b0 = -1.0, -0.1\n",
    "  w1, b1 = 0.1, 1.0\n",
    "  w2, b2 = 1.1, -0.1\n",
    "\n",
    "  y0 = w0 * x.numpy() + b0\n",
    "  y1 = w1 * x.numpy() + b1\n",
    "  y2 = w2 * x.numpy() + b2\n",
    "\n",
    "  ax.plot(x.numpy(), y0, 'b-', label='$z_0$')\n",
    "  ax.plot(x.numpy(), y1, 'r-', label='$z_1$')\n",
    "  ax.plot(x.numpy(), y2, 'g-', label='$z_2$')\n",
    "\n",
    "  ax.set_ylim(bottom=-0.05, top=1.9)\n",
    "\n",
    "  ax.legend(loc=0)\n",
    "\n",
    "  return ax\n",
    "\n",
    "\n",
    "ax = plot_softmax_data_00(x, y)\n",
    "ax = plot_softmax_lines_01(x, ax=ax)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2D\n",
    "* MNIST dataset\n",
    "* See classification results as vectors\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* take a look at the MNIST data\n",
    "* Following cell would only work in Google Colab\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "@functools.lru_cache\n",
    "def read_sample_data():\n",
    "\n",
    "  sample_data_path = pathlib.Path('sample_data')\n",
    "  assert sample_data_path.exists()\n",
    "  assert sample_data_path.is_dir()\n",
    "\n",
    "  mnist_path = sample_data_path / 'mnist_train_small.csv'\n",
    "  assert mnist_path.exists()\n",
    "  assert mnist_path.is_file()\n",
    "\n",
    "  df_mnist = pd.read_csv(mnist_path)\n",
    "\n",
    "  y = df_mnist.iloc[:, 0].astype(int)\n",
    "  x = df_mnist.iloc[:, 1:].astype(int)\n",
    "\n",
    "  return {'x': x, 'y': y}\n",
    "\n",
    "\n",
    "@functools.lru_cache\n",
    "def get_x_of_y(y:int, d_xy=None):\n",
    "  if d_xy is None:\n",
    "    d_xy = read_sample_data()\n",
    "\n",
    "  return d_xy['x'].loc[y == d_xy['y'], :]\n",
    "\n",
    "\n",
    "def get_x_i(y:int, i:int=None, x_of_y=None, shape=(28, 28)):\n",
    "  if x_of_y is None:\n",
    "    x_of_y = get_x_of_y(y)\n",
    "\n",
    "  if i is None:\n",
    "    i = random.randint(0, x_of_y.shape[0])\n",
    "\n",
    "  return np.array(x_of_y.iloc[i, :]).reshape(*shape)\n",
    "\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  # TODO : if not Google Colab, read from torchvision\n",
    "  random.seed()\n",
    "  _, axs = plt.subplots(3, 3)\n",
    "  for y, ax in enumerate(axs.flatten()):\n",
    "    x_i = get_x_i(y)\n",
    "    ax.imshow(x_i);\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2 Softmax Function\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Custom module\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Softmax(torch.nn.Module):\n",
    "  def __init__(self, in_size:int, out_size:int):\n",
    "    super(Softmax, self).__init__()\n",
    "    self.linear = torch.nn.Linear(in_size, out_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.linear(x)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = Softmax(3, 3)\n",
    "\n",
    "X = torch.tensor([\n",
    "    [3.0, 1.0, 0.1],\n",
    "    [0.0, 2.0, 1.0],\n",
    "    [1.0, 2.0, 3.0],\n",
    "])\n",
    "\n",
    "z = model(X)\n",
    "_, yhat = z.max(1)\n",
    "\n",
    "print(z)\n",
    "\n",
    "print(yhat)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.3 Softmax PyTorch\n",
    "* Load Data\n",
    "* Create Model\n",
    "* Train Model\n",
    "* View Results\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load Data\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torchvision.transforms\n",
    "import torchvision.datasets\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@functools.lru_cache\n",
    "def load_MNIST_torchvision():\n",
    "  '''\n",
    "  [[image, class], ...]\n",
    "  '''\n",
    "\n",
    "  train_dataset = torchvision.datasets.MNIST(\n",
    "      root='./data',\n",
    "      train=True,\n",
    "      download=True,\n",
    "      transform=torchvision.transforms.ToTensor(),\n",
    "  )\n",
    "\n",
    "  test_dataset = torchvision.datasets.MNIST(\n",
    "      root='./data',\n",
    "      train=False,\n",
    "      download=True,\n",
    "      transform=torchvision.transforms.ToTensor(),\n",
    "  )\n",
    "\n",
    "  return {\n",
    "      'train': train_dataset,\n",
    "      'validation': test_dataset,\n",
    "  }\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "d_mnist = load_MNIST_torchvision()\n",
    "x0, y0 = random.choice(d_mnist['train'])\n",
    "ax = plt.imshow(np.squeeze(x0))\n",
    "plt.title(f'y = {y0}');\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Model\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10\n",
    "\n",
    "model = Softmax(input_dim, output_dim)\n",
    "z = model(x0.flatten())\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('W:', list(model.parameters())[0].size())\n",
    "print('b:', list(model.parameters())[1].size())\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def PlotParameters(model):\n",
    "  _, axs = plt.subplots(2, 5)\n",
    "  w_3d = list(model.parameters())[0]\n",
    "  for k, (w_2d, ax) in enumerate(zip(w_3d, axs.flatten())):\n",
    "    ax.imshow(w_2d.detach().numpy().reshape(28, 28))\n",
    "    ax.set_xlabel(f'Weights : {k}')\n",
    "\n",
    "\n",
    "PlotParameters(model)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "n_epochs = 100\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=d_mnist['train'], batch_size=100,\n",
    ")\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    dataset=d_mnist['validation'], batch_size=5000,\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train Model\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "N_test = len(d_mnist['validation'])\n",
    "accuracy_list = []\n",
    "\n",
    "if os.environ.get('CI', False):\n",
    "  n_epochs = 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  for x, y in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    z = model(x.view(-1, 28*28))\n",
    "    loss = criterion(z, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  correct = 0\n",
    "\n",
    "  for x_test, y_test in validation_loader:\n",
    "    z = model(x_test.view(-1, 28*28))\n",
    "    _, yhat = torch.max(z.data, 1)\n",
    "\n",
    "    correct += (yhat == y_test).sum().item()\n",
    "  accuracy = correct / N_test\n",
    "  accuracy_list.append(accuracy)\n",
    "\n",
    "  print(f\"{epoch:4d} {accuracy:.6} {(time.time() - start_time):16.4f}\")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.stem(accuracy_list)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### View Results\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "PlotParameters(model)\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shallow Neural Networks\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.1 Neural Networks in One Dimension\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Net(torch.nn.Module):\n",
    "  def __init__(self, *argv, **kwarg):\n",
    "    super(Net, self).__init__()\n",
    "\n",
    "    self.layers = []\n",
    "    for n_in, n_out in (argv[:-1], argv[1:]):\n",
    "      self.layers.append(torch.nn.Linear(n_in, n_out))\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    for layer in self.layers:\n",
    "      x = torch.sigmoid(layer(x))\n",
    "\n",
    "    return x\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = Net(1, 2, 1)\n",
    "\n",
    "x = torch.tensor([0.0])\n",
    "yhat = model(x)\n",
    "\n",
    "yhat\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.2 Neural Networks More Hidden Neurons\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.3 Neural Networks with Multiple Dimensional Input\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.4 Multi-Class Neural Networks\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.5 Backpropagation\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7.6 Activation Function\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}