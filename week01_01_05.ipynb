{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kangwonlee/pytorch-ibm-coursera/blob/main/week01_01_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello PyTorch üëãüèª\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "references\n",
    "* https://www.coursera.org/learn/deep-neural-networks-with-pytorch/\n",
    "* https://github.com/damounayman/Deep-Neural-Networks-with-PyTorch/blob/main/Week1/1D_tensors.ipynb\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## week 1\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.5 Dataset\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataset Class\n",
    "for images\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import gzip\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import torch.utils.data\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "dataset :\n",
    "* https://github.com/zalandoresearch/fashion-mnist\n",
    "* 28 x 28 bitmaps\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png\" width=300 height=300></img>\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "try:\n",
    "  repo_path = pathlib.Path('fashion-mnist')\n",
    "  assert repo_path.exists()\n",
    "except AssertionError:\n",
    "  import subprocess\n",
    "  p = subprocess.run(\n",
    "      ['git', 'clone', 'https://github.com/zalandoresearch/fashion-mnist'],\n",
    "      stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "      encoding='utf-8',\n",
    "  )\n",
    "  assert (0 == p.returncode), (\n",
    "      '\\n'\n",
    "      f\"code : {p.check_returncode}\\n\"\n",
    "      f\"output : {p.stdout}\\n\"\n",
    "      f\"error  : {p.stderr}\"\n",
    "  )\n",
    "\n",
    "assert repo_path.is_dir()\n",
    "data_utils_path = (repo_path / 'utils').resolve()\n",
    "assert data_utils_path.exists()\n",
    "assert data_utils_path.is_dir()\n",
    "\n",
    "sys.path.insert(0, str(repo_path / 'utils'))\n",
    "\n",
    "import mnist_reader\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fashion_path = repo_path / 'data' / 'fashion'\n",
    "assert fashion_path.exists()\n",
    "assert fashion_path.is_dir()\n",
    "\n",
    "X_train, y_train = mnist_reader.load_mnist(fashion_path, kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist(fashion_path, kind='t10k')\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "To reset repo :\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "#!rm -rf fashion-mnist/\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, data_path=fashion_path, transform=None):\n",
    "    self.transform = transform\n",
    "    self.data_path = data_path\n",
    "    self.y_train = self.read_labels()\n",
    "    self.len = self.y_train.shape[0]\n",
    "\n",
    "  def read_labels(self, kind='train'):\n",
    "    labels_path = self.data_path / f'{kind}-labels-idx1-ubyte.gz'\n",
    "    assert labels_path.exists\n",
    "    assert labels_path.is_file()\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as f_labels:\n",
    "      labels = np.frombuffer(\n",
    "        f_labels.read(),\n",
    "        dtype=np.uint8,\n",
    "        offset=8,\n",
    "      )\n",
    "\n",
    "    return labels\n",
    "\n",
    "  def read_image(self, k, kind='train'):\n",
    "    image_path = self.data_path / f'{kind}-images-idx3-ubyte.gz'\n",
    "    assert image_path.exists\n",
    "    assert image_path.is_file()\n",
    "\n",
    "    # TODO : save memory\n",
    "    with gzip.open(image_path, 'rb') as f_images:\n",
    "      images = np.frombuffer(\n",
    "        f_images.read(),\n",
    "        dtype=np.uint8,\n",
    "        offset=16,\n",
    "      ).reshape(self.len, 784)\n",
    "\n",
    "    return images[k]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = PIL.Image.fromarray(self.read_image(idx).reshape(28, 28))\n",
    "    y = self.y_train[idx]\n",
    "\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    return image, y\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "lookup = (\n",
    "  'T-shirt/top', 'Trouser', 'Pullover',\n",
    "  'Dress', 'Coat', 'Sandal',\n",
    "  'Shirt', 'Sneaker', 'Bag',\n",
    "  'Ankle boot',\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = Dataset()\n",
    "n_subplots = 5\n",
    "_, axs = plt.subplots(n_subplots, 1,figsize=(9, 16))\n",
    "for k in range(n_subplots):\n",
    "  x, y = dataset[k]\n",
    "  axs[k].imshow(x)\n",
    "  axs[k].set_title(lookup[y])\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Declare data transform\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torchvision.transforms\n",
    "\n",
    "croptensor_data_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.CenterCrop(20),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = Dataset(transform=croptensor_data_transform)\n",
    "n_subplots = 5\n",
    "_, axs = plt.subplots(n_subplots, 1,figsize=(9, 16))\n",
    "for k in range(n_subplots):\n",
    "  x, y = dataset[k]\n",
    "  axs[k].imshow(x.squeeze()) # [1, 28, 28] -> [28, 28]\n",
    "  axs[k].set_title((x.shape,lookup[y]))\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dataset\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import torchvision.datasets\n",
    "\n",
    "mnist_root_path = pathlib.Path('mnist')\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(\n",
    "    root=mnist_root_path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}